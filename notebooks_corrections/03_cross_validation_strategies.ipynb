{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ae77448",
   "metadata": {},
   "source": [
    "\n",
    "# Cross-validation strategies\n",
    "\n",
    "The previous notebooks introduced how to evaluate a model and how to create a\n",
    "specific preprocessing pipeline depending of the last model.\n",
    "\n",
    "In this notebook, we will check a bit more some details regarding the cross-validation\n",
    "strategies and some of the pitfalls that we can encounter.\n",
    "\n",
    "Let's take iris dataset and evaluate a logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556bb167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "df, target = load_iris(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aae1e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49588fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5234e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "logistic_regression = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "logistic_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d497b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_validate, KFold\n",
    "\n",
    "cv = KFold(n_splits=3)\n",
    "cv_results = cross_validate(\n",
    "    logistic_regression, df, target, cv=cv, return_train_score=True\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results[[\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb2d056",
   "metadata": {},
   "source": [
    "\n",
    "We observe that the training score is always zero that is really surprising. We can\n",
    "check the target to understand why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ed71d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = target.plot()\n",
    "_ = ax.set(\n",
    "    xlabel=\"Sample index\",\n",
    "    ylabel=\"Target value\",\n",
    "    title=\"Iris dataset target values\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1b2118",
   "metadata": {},
   "source": [
    "\n",
    "We observe that the data is ordered by target. This is a problem because the KFold\n",
    "object is not shuffling the data before splitting it. Therefore, we always get a\n",
    "test set that does not contain a class seen during `fit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb01825",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv_fold_idx, (train_indices, test_indices) in enumerate(cv.split(df, target)):\n",
    "    print(f\"Fold {cv_fold_idx}:\\n\")\n",
    "    print(\n",
    "        f\"Class counts on the train set:\\n\"\n",
    "        f\"{target.iloc[train_indices].value_counts()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Class counts on the test set:\\n\" f\"{target.iloc[test_indices].value_counts()}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2be9a",
   "metadata": {},
   "source": [
    "\n",
    "We can use a `StratifiedKFold` object to ensure that the class distribution is\n",
    "preserved in each fold. A side effect will be that all classes will be present in the\n",
    "training set and testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ea82ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=3)\n",
    "cv_results = cross_validate(\n",
    "    logistic_regression, df, target, cv=cv, return_train_score=True\n",
    ")\n",
    "cv_results = pd.DataFrame(cv_results)\n",
    "cv_results[[\"train_score\", \"test_score\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a507ac37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv_fold_idx, (train_indices, test_indices) in enumerate(cv.split(df, target)):\n",
    "    print(f\"Fold {cv_fold_idx}:\\n\")\n",
    "    print(\n",
    "        f\"Class counts on the train set:\\n\"\n",
    "        f\"{target.iloc[train_indices].value_counts()}\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Class counts on the test set:\\n\" f\"{target.iloc[test_indices].value_counts()}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87a04e7",
   "metadata": {},
   "source": [
    "\n",
    "This is particularly useful when we have imbalanced classes. Let's check the class\n",
    "distribution of the breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6790d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "df, target = load_breast_cancer(as_frame=True, return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78cf787",
   "metadata": {},
   "outputs": [],
   "source": [
    "target.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0f7f0",
   "metadata": {},
   "source": [
    "\n",
    "Here, we see that the proportion of the two classes is not equal. We can check the\n",
    "class distribution in each fold using a `KFold` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8549d12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "for cv_fold_idx, (train_indices, test_indices) in enumerate(cv.split(df, target)):\n",
    "    print(f\"Fold {cv_fold_idx}:\\n\")\n",
    "    print(\n",
    "        \"Class counts on the train set:\\n\"\n",
    "        f\"{target.iloc[train_indices].value_counts(normalize=True)}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Class counts on the test set:\\n\"\n",
    "        f\"{target.iloc[test_indices].value_counts(True)}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f54ef5a",
   "metadata": {},
   "source": [
    "\n",
    "We observe that the class distribution is not preserved in each fold. We can use a\n",
    "`StratifiedKFold` object to ensure that the class distribution is preserved in each\n",
    "fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11447a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3)\n",
    "for cv_fold_idx, (train_indices, test_indices) in enumerate(cv.split(df, target)):\n",
    "    print(f\"Fold {cv_fold_idx}:\\n\")\n",
    "    print(\n",
    "        \"Class counts on the train set:\\n\"\n",
    "        f\"{target.iloc[train_indices].value_counts(normalize=True)}\\n\"\n",
    "    )\n",
    "    print(\n",
    "        f\"Class counts on the test set:\\n\"\n",
    "        f\"{target.iloc[test_indices].value_counts(True)}\"\n",
    "    )\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c31f278",
   "metadata": {},
   "source": [
    "\n",
    "Now, let's check the documentation of the `cross_validate` function to see if this\n",
    "function was already providing a way to stratify the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee7cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "help(cross_validate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86c8f5",
   "metadata": {},
   "source": [
    "\n",
    "Now, we will look at the notion of `groups` in cross-validation. We will use the\n",
    "digits dataset and group the samples by writer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "df, target = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab96f636",
   "metadata": {},
   "source": [
    "\n",
    "We create a simple model that is a logistic regression model with a scaling of the\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f0d43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "logistic_regression = make_pipeline(MinMaxScaler(), LogisticRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c83e46",
   "metadata": {},
   "source": [
    "\n",
    "Let's start to evaluate the model using a `KFold` object, once without shuffling and\n",
    "once with shuffling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06afb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=13)\n",
    "cv_results = cross_validate(logistic_regression, df, target, cv=cv)\n",
    "print(\n",
    "    f\"Mean test score: {cv_results['test_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711a93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = KFold(n_splits=13, shuffle=True, random_state=0)\n",
    "cv_results = cross_validate(logistic_regression, df, target, cv=cv)\n",
    "print(\n",
    "    f\"Mean test score: {cv_results['test_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44bdd16",
   "metadata": {},
   "source": [
    "\n",
    "Surprisingly, the mean test score is increasing when shuffling the data. Let's check\n",
    "if this is due to the random seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af00f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for seed in range(10):\n",
    "    cv = KFold(n_splits=13, shuffle=True, random_state=seed)\n",
    "    cv_results = cross_validate(logistic_regression, df, target, cv=cv)\n",
    "    print(\n",
    "        f\"Mean test score: {cv_results['test_score'].mean():.3f} +/- \"\n",
    "        f\"{cv_results['test_score'].std():.3f}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876e575f",
   "metadata": {},
   "source": [
    "\n",
    "Apparently not. The reason is that the samples are grouped by writer. By shuffling,\n",
    "we are mixing the samples from different writers. Therefore, we are learning a model\n",
    "on some writers that are also used to test. However, if we want to have a model that\n",
    "generalizes well to new writers, we should not mix the samples from the same writer\n",
    "between the training and testing set.\n",
    "\n",
    "Here, we provide a `groups` array that mentioned the writer ID for each sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import count\n",
    "import numpy as np\n",
    "\n",
    "# defines the lower and upper bounds of sample indices\n",
    "# for each writer\n",
    "writer_boundaries = [\n",
    "    0,\n",
    "    130,\n",
    "    256,\n",
    "    386,\n",
    "    516,\n",
    "    646,\n",
    "    776,\n",
    "    915,\n",
    "    1029,\n",
    "    1157,\n",
    "    1287,\n",
    "    1415,\n",
    "    1545,\n",
    "    1667,\n",
    "    1797,\n",
    "]\n",
    "groups = np.zeros_like(target)\n",
    "lower_bounds = writer_boundaries[:-1]\n",
    "upper_bounds = writer_boundaries[1:]\n",
    "\n",
    "for group_id, lb, up in zip(count(), lower_bounds, upper_bounds):\n",
    "    groups[lb:up] = group_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4c6981",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(groups)\n",
    "plt.yticks(np.unique(groups))\n",
    "plt.xticks(writer_boundaries, rotation=90)\n",
    "plt.xlabel(\"Target index\")\n",
    "plt.ylabel(\"Writer index\")\n",
    "_ = plt.title(\"Underlying writer groups existing in the target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d848c6c2",
   "metadata": {},
   "source": [
    "\n",
    "We can use this information to properly evaluate our model. We need to use the\n",
    "`GroupKFold` object and pass the `groups` parameter to the `cross_validate` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e15fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "cv = GroupKFold(n_splits=13)\n",
    "cv_results = cross_validate(logistic_regression, df, target, groups=groups, cv=cv)\n",
    "print(\n",
    "    f\"Mean test score: {cv_results['test_score'].mean():.3f} +/- \"\n",
    "    f\"{cv_results['test_score'].std():.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfd0b1c",
   "metadata": {},
   "source": [
    "\n",
    "We observe that the mean test score is even lower but certainly closer to the true\n",
    "performance of the model."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
